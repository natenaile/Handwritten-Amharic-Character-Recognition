{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1697a129-4f72-4259-bc95-95538c569711",
      "metadata": {
        "id": "1697a129-4f72-4259-bc95-95538c569711"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31da89d0-f44b-42a1-9e50-ddc18469c743",
      "metadata": {
        "id": "31da89d0-f44b-42a1-9e50-ddc18469c743",
        "outputId": "7bc8e0da-a7b0-4879-996e-4ef93f7ca9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample batch shape: torch.Size([64, 1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.9, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "data_dir = r'C:\\Users\\aaa\\Documents\\DATASETS\\Organized_Amharic_Character_Dataset'\n",
        "dataset = ImageFolder(root=data_dir, transform=transform)\n",
        "targets = np.array(dataset.targets)\n",
        "\n",
        "train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=targets, random_state=42)\n",
        "train_subset = Subset(dataset, train_indices)\n",
        "val_subset = Subset(dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Sample batch shape: {images.shape}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e774fe-6d93-4a04-a1d2-44bec8cc4dd7",
      "metadata": {
        "id": "43e774fe-6d93-4a04-a1d2-44bec8cc4dd7",
        "outputId": "f8124d4f-d9f2-4667-8f9e-56af972ccb60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Extracting training features...\n",
            "Extracted features for batch 1\n",
            "Extracted features for batch 11\n",
            "Extracted features for batch 21\n",
            "Extracted features for batch 31\n",
            "Extracted features for batch 41\n",
            "Extracted features for batch 51\n",
            "Extracted features for batch 61\n",
            "Extracted features for batch 71\n",
            "Extracted features for batch 81\n",
            "Extracted features for batch 91\n",
            "Extracted features for batch 101\n",
            "Extracted features for batch 111\n",
            "Extracted features for batch 121\n",
            "Extracted features for batch 131\n",
            "Extracted features for batch 141\n",
            "Extracted features for batch 151\n",
            "Extracted features for batch 161\n",
            "Extracted features for batch 171\n",
            "Extracted features for batch 181\n",
            "Extracted features for batch 191\n",
            "Extracted features for batch 201\n",
            "Extracted features for batch 211\n",
            "Extracted features for batch 221\n",
            "Extracted features for batch 231\n",
            "Extracted features for batch 241\n",
            "Extracted features for batch 251\n",
            "Extracted features for batch 261\n",
            "Extracted features for batch 271\n",
            "Extracted features for batch 281\n",
            "Extracted features for batch 291\n",
            "Extracted features for batch 301\n",
            "Extracted features for batch 311\n",
            "Extracted features for batch 321\n",
            "Extracted features for batch 331\n",
            "Extracted features for batch 341\n",
            "Extracted features for batch 351\n",
            "Extracted features for batch 361\n",
            "Extracted features for batch 371\n",
            "Extracted features for batch 381\n",
            "Extracted features for batch 391\n",
            "Extracted features for batch 401\n",
            "Extracted features for batch 411\n",
            "Extracted features for batch 421\n",
            "Extracted features for batch 431\n",
            "Extracted features for batch 441\n",
            "Extracted features for batch 451\n",
            "Extracted features for batch 461\n",
            "Extracted features for batch 471\n",
            "Finished extracting training features.\n",
            "Step 2: Extracting validation features...\n",
            "Extracted features for batch 1\n",
            "Extracted features for batch 11\n",
            "Extracted features for batch 21\n",
            "Extracted features for batch 31\n",
            "Extracted features for batch 41\n",
            "Extracted features for batch 51\n",
            "Extracted features for batch 61\n",
            "Extracted features for batch 71\n",
            "Extracted features for batch 81\n",
            "Extracted features for batch 91\n",
            "Extracted features for batch 101\n",
            "Extracted features for batch 111\n",
            "Finished extracting validation features.\n",
            "Step 3: Training Random Forest Classifier...\n",
            "Finished training Random Forest Classifier.\n",
            "Step 4: Evaluating on training data...\n",
            "Training Accuracy: 0.9676\n",
            "Training Precision: 0.9702\n",
            "Training Recall: 0.9676\n",
            "Training F1 Score: 0.9673\n",
            "Step 5: Evaluating on validation data...\n",
            "Validation Accuracy: 0.9004\n",
            "Validation Precision: 0.9087\n",
            "Validation Recall: 0.9004\n",
            "Validation F1 Score: 0.9001\n",
            "Model saved as rf_model_vgg19.pkl\n",
            "All steps completed!\n"
          ]
        }
      ],
      "source": [
        "#VGG19\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg19_base = models.vgg19(weights='DEFAULT')\n",
        "vgg19_base.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "vgg19_base.classifier = nn.Sequential(*list(vgg19_base.classifier.children())[:-1])\n",
        "\n",
        "class CustomVGG19(nn.Module):\n",
        "    def __init__(self, base_model, num_classes):\n",
        "        super(CustomVGG19, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.fc = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "num_classes = 238\n",
        "model_2 = CustomVGG19(vgg19_base, num_classes).to(device)\n",
        "\n",
        "model_2.load_state_dict(torch.load(r'C:\\Users\\aaa\\RESEARCH\\model_2_weights.pth', weights_only=True))\n",
        "\n",
        "def extract_features(dataloader, model):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            features.append(outputs.cpu().numpy())\n",
        "            labels.append(targets.numpy())\n",
        "            if i % 10 == 0:  # Track progress every 10 batches\n",
        "                print(f\"Extracted features for batch {i+1}\")\n",
        "    return np.concatenate(features), np.concatenate(labels)\n",
        "\n",
        "print(\"Step 1: Extracting training features...\")\n",
        "train_features, train_labels = extract_features(train_loader, model_2)\n",
        "print(\"Finished extracting training features.\")\n",
        "\n",
        "print(\"Step 2: Extracting validation features...\")\n",
        "val_features, val_labels = extract_features(val_loader, model_2)\n",
        "print(\"Finished extracting validation features.\")\n",
        "#VGG19+RANDOM FOREST\n",
        "print(\"Step 3: Training Random Forest Classifier...\")\n",
        "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf_classifier.fit(train_features, train_labels)\n",
        "print(\"Finished training Random Forest Classifier.\")\n",
        "\n",
        "def evaluate_in_batches(dataloader, model, classifier):\n",
        "    model.eval()\n",
        "    batch_acc = []\n",
        "    batch_prec = []\n",
        "    batch_rec = []\n",
        "    batch_f1 = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = classifier.predict(outputs.cpu().numpy())\n",
        "\n",
        "            acc = accuracy_score(targets.numpy(), preds)\n",
        "            prec = precision_score(targets.numpy(), preds, average='weighted', zero_division=0)\n",
        "            rec = recall_score(targets.numpy(), preds, average='weighted', zero_division=0)\n",
        "            f1 = f1_score(targets.numpy(), preds, average='weighted', zero_division=0)\n",
        "\n",
        "            batch_acc.append(acc)\n",
        "            batch_prec.append(prec)\n",
        "            batch_rec.append(rec)\n",
        "            batch_f1.append(f1)\n",
        "\n",
        "    avg_acc = np.mean(batch_acc)\n",
        "    avg_prec = np.mean(batch_prec)\n",
        "    avg_rec = np.mean(batch_rec)\n",
        "    avg_f1 = np.mean(batch_f1)\n",
        "\n",
        "    return avg_acc, avg_prec, avg_rec, avg_f1\n",
        "\n",
        "print(\"Step 4: Evaluating on training data...\")\n",
        "train_avg_acc, train_avg_prec, train_avg_rec, train_avg_f1 = evaluate_in_batches(train_loader, model_2, rf_classifier)\n",
        "\n",
        "print(f\"Training Accuracy: {train_avg_acc:.4f}\")\n",
        "print(f\"Training Precision: {train_avg_prec:.4f}\")\n",
        "print(f\"Training Recall: {train_avg_rec:.4f}\")\n",
        "print(f\"Training F1 Score: {train_avg_f1:.4f}\")\n",
        "\n",
        "print(\"Step 5: Evaluating on validation data...\")\n",
        "val_avg_acc, val_avg_prec, val_avg_rec, val_avg_f1 = evaluate_in_batches(val_loader, model_2, rf_classifier)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_avg_acc:.4f}\")\n",
        "print(f\"Validation Precision: {val_avg_prec:.4f}\")\n",
        "print(f\"Validation Recall: {val_avg_rec:.4f}\")\n",
        "print(f\"Validation F1 Score: {val_avg_f1:.4f}\")\n",
        "\n",
        "joblib.dump(rf_classifier, 'rf_model_vgg19.pkl')\n",
        "print(\"Model saved as rf_model_vgg19.pkl\")\n",
        "\n",
        "print(\"All steps completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ddfb37-aa14-40d7-9507-a9262c3f92ac",
      "metadata": {
        "id": "f8ddfb37-aa14-40d7-9507-a9262c3f92ac",
        "outputId": "b392b55f-91f8-44ad-f944-3c31bf54fcbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XGBoost Classifier...\n",
            "Finished training XGBoost Classifier.\n",
            "Evaluating on training data...\n",
            "Training Accuracy: 0.9526\n",
            "Training Precision: 0.9572\n",
            "Training Recall: 0.9526\n",
            "Training F1 Score: 0.9525\n",
            "Evaluating on validation data...\n",
            "Validation Accuracy: 0.8817\n",
            "Validation Precision: 0.8943\n",
            "Validation Recall: 0.8817\n",
            "Validation F1 Score: 0.8824\n",
            "Model saved as xgb_model_vgg19.pkl\n",
            "All steps completed!\n"
          ]
        }
      ],
      "source": [
        "#VGG-19+XGBOOST\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier, DMatrix\n",
        "import joblib\n",
        "\n",
        "print(\"Training XGBoost Classifier...\")\n",
        "xgb_classifier = XGBClassifier(\n",
        "    eval_metric='mlogloss',\n",
        "    n_estimators=200,\n",
        "    random_state=42,\n",
        "    tree_method='hist',\n",
        "    device='cuda'\n",
        ")\n",
        "xgb_classifier.fit(train_features, train_labels)\n",
        "print(\"Finished training XGBoost Classifier.\")\n",
        "\n",
        "print(\"Evaluating on training data...\")\n",
        "train_avg_acc, train_avg_prec, train_avg_rec, train_avg_f1 = evaluate_in_batches(train_loader, model_2, xgb_classifier)\n",
        "\n",
        "print(f\"Training Accuracy: {train_avg_acc:.4f}\")\n",
        "print(f\"Training Precision: {train_avg_prec:.4f}\")\n",
        "print(f\"Training Recall: {train_avg_rec:.4f}\")\n",
        "print(f\"Training F1 Score: {train_avg_f1:.4f}\")\n",
        "\n",
        "print(\"Evaluating on validation data...\")\n",
        "val_avg_acc, val_avg_prec, val_avg_rec, val_avg_f1 = evaluate_in_batches(val_loader, model_2, xgb_classifier)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_avg_acc:.4f}\")\n",
        "print(f\"Validation Precision: {val_avg_prec:.4f}\")\n",
        "print(f\"Validation Recall: {val_avg_rec:.4f}\")\n",
        "print(f\"Validation F1 Score: {val_avg_f1:.4f}\")\n",
        "\n",
        "joblib.dump(xgb_classifier, 'xgb_model_vgg19.pkl')\n",
        "print(\"Model saved as xgb_model_vgg19.pkl\")\n",
        "\n",
        "print(\"All steps completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04825f00-d866-4be8-8b0d-890dfc21c676",
      "metadata": {
        "id": "04825f00-d866-4be8-8b0d-890dfc21c676",
        "outputId": "ff211daa-d295-4410-f1cc-7b618e02a690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training SVM Classifier...\n",
            "Finished training SVM Classifier.\n",
            "Evaluating on training data...\n",
            "Training Accuracy: 0.9601\n",
            "Training Precision: 0.9642\n",
            "Training Recall: 0.9601\n",
            "Training F1 Score: 0.9600\n",
            "Evaluating on validation data...\n",
            "Validation Accuracy: 0.9017\n",
            "Validation Precision: 0.9097\n",
            "Validation Recall: 0.9017\n",
            "Validation F1 Score: 0.9011\n",
            "Model saved as svm_model_vgg19.pkl\n",
            "All steps completed!\n"
          ]
        }
      ],
      "source": [
        "#VGG-19+SVM\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "import joblib\n",
        "\n",
        "print(\"Training SVM Classifier...\")\n",
        "svm_classifier = SVC(kernel='rbf', random_state=42, gamma='scale')\n",
        "svm_classifier.fit(train_features, train_labels)\n",
        "print(\"Finished training SVM Classifier.\")\n",
        "\n",
        "print(\"Evaluating on training data...\")\n",
        "train_avg_acc, train_avg_prec, train_avg_rec, train_avg_f1 = evaluate_in_batches(train_loader, model_2, svm_classifier)\n",
        "\n",
        "print(f\"Training Accuracy: {train_avg_acc:.4f}\")\n",
        "print(f\"Training Precision: {train_avg_prec:.4f}\")\n",
        "print(f\"Training Recall: {train_avg_rec:.4f}\")\n",
        "print(f\"Training F1 Score: {train_avg_f1:.4f}\")\n",
        "\n",
        "print(\"Evaluating on validation data...\")\n",
        "val_avg_acc, val_avg_prec, val_avg_rec, val_avg_f1 = evaluate_in_batches(val_loader, model_2, svm_classifier)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_avg_acc:.4f}\")\n",
        "print(f\"Validation Precision: {val_avg_prec:.4f}\")\n",
        "print(f\"Validation Recall: {val_avg_rec:.4f}\")\n",
        "print(f\"Validation F1 Score: {val_avg_f1:.4f}\")\n",
        "\n",
        "joblib.dump(svm_classifier, 'svm_model_vgg19.pkl')\n",
        "print(\"Model saved as svm_model_vgg19.pkl\")\n",
        "\n",
        "print(\"All steps completed!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (dl_project)",
      "language": "python",
      "name": "dl_project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}